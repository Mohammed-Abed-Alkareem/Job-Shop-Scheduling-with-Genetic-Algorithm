{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from Genetic_Algoritm.genetic_algorithm import genetic_algorithm\n",
    "from Data.read_csv import dictionary_store\n",
    "from Genetic_Algoritm.Fitness_Functions import *\n",
    "from Genetic_Algoritm.Crossover_Functions import *"
   ],
   "id": "f13432e1a84fc9cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "Jobs = dictionary_store(\"Data\\\\job_shop_schedule.csv\")",
   "id": "d4e6d063d67a8648",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## partially_mapped_crossover",
   "id": "9c71c7c231570c6f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import multiprocessing\n",
    "\n",
    "# Function to run\n",
    "def run():\n",
    "    best_chromosome, best_fitness, gen = genetic_algorithm(Jobs, population_size=8, generations=500,\n",
    "                      mutation_rate=0.01, fitness_function=get_makespan, satisfication_vlue=0,\n",
    "                      crossover_function=partially_mapped_crossover)\n",
    "    return gen\n",
    "\n",
    "# Number of iterations\n",
    "num_iterations = 100\n",
    "\n",
    "# Define a function for parallel execution\n",
    "def parallel_run(index):\n",
    "    print(f\"Running iteration {index}\")\n",
    "    return index, run()  # Return both the iteration index and the result\n",
    "\n",
    "# Number of CPU cores\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(num_cores)\n",
    "\n",
    "# Run the loop in parallel\n",
    "with multiprocessing.Pool(num_cores) as pool:\n",
    "    results = pool.map(parallel_run, range(num_iterations))\n",
    "\n",
    "# Sort results based on the iteration index\n",
    "results.sort(key=lambda x: x[0])\n",
    "\n",
    "# Extract only the results and store them in a list\n",
    "iterations_results = [result[1] for result in results]\n",
    "\n",
    "# Print the results (optional)\n",
    "print(iterations_results)"
   ],
   "id": "34c066e510bd7c0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Combine lists into a DataFrame\n",
    "df = pd.DataFrame(iterations_results)\n",
    "\n",
    "# File path to save CSV\n",
    "file_path = 'partially_mapped_crossover.csv'\n",
    "\n",
    "# Write DataFrame to CSV\n",
    "df.to_csv(file_path, index=False, header=False)\n",
    "\n",
    "print(f\"Data has been saved to {file_path}\")"
   ],
   "id": "6e6f44861bbfb7df"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## single_segment_crossover",
   "id": "7f27762683895625"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import multiprocessing\n",
    "\n",
    "# Function to run\n",
    "def run():\n",
    "    best_chromosome, best_fitness, gen = genetic_algorithm(Jobs, population_size=8, generations=500,\n",
    "                      mutation_rate=0.01, fitness_function=get_makespan, satisfication_vlue=0,\n",
    "                      crossover_function=single_segment_crossover)\n",
    "    return gen\n",
    "\n",
    "# Number of iterations\n",
    "num_iterations = 100\n",
    "\n",
    "# Define a function for parallel execution\n",
    "def parallel_run(index):\n",
    "    print(f\"Running iteration {index}\")\n",
    "    return index, run()  # Return both the iteration index and the result\n",
    "\n",
    "# Number of CPU cores\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(num_cores)\n",
    "\n",
    "# Run the loop in parallel\n",
    "with multiprocessing.Pool(num_cores) as pool:\n",
    "    results = pool.map(parallel_run, range(num_iterations))\n",
    "\n",
    "# Sort results based on the iteration index\n",
    "results.sort(key=lambda x: x[0])\n",
    "\n",
    "# Extract only the results and store them in a list\n",
    "iterations_results = [result[1] for result in results]\n",
    "\n",
    "# Print the results (optional)\n",
    "print(iterations_results)"
   ],
   "id": "18705f3e8bac0a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Combine lists into a DataFrame\n",
    "df = pd.DataFrame(iterations_results)\n",
    "\n",
    "# File path to save CSV\n",
    "file_path = 'single_segment_crossover.csv'\n",
    "\n",
    "# Write DataFrame to CSV\n",
    "df.to_csv(file_path, index=False, header=False)\n",
    "\n",
    "print(f\"Data has been saved to {file_path}\")"
   ],
   "id": "a54bd7279b82f69a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## double_segment_crossover",
   "id": "22f750f642af91ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import multiprocessing\n",
    "\n",
    "# Function to run\n",
    "def run():\n",
    "    best_chromosome, best_fitness, gen = genetic_algorithm(Jobs, population_size=8, generations=500,\n",
    "                      mutation_rate=0.01, fitness_function=get_makespan, satisfication_vlue=0,\n",
    "                      crossover_function=double_segment_crossover)\n",
    "    return gen\n",
    "\n",
    "# Number of iterations\n",
    "num_iterations = 100\n",
    "\n",
    "# Define a function for parallel execution\n",
    "def parallel_run(index):\n",
    "    print(f\"Running iteration {index}\")\n",
    "    return index, run()  # Return both the iteration index and the result\n",
    "\n",
    "# Number of CPU cores\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(num_cores)\n",
    "\n",
    "# Run the loop in parallel\n",
    "with multiprocessing.Pool(num_cores) as pool:\n",
    "    results = pool.map(parallel_run, range(num_iterations))\n",
    "\n",
    "# Sort results based on the iteration index\n",
    "results.sort(key=lambda x: x[0])\n",
    "\n",
    "# Extract only the results and store them in a list\n",
    "iterations_results = [result[1] for result in results]\n",
    "\n",
    "# Print the results (optional)\n",
    "print(iterations_results)"
   ],
   "id": "c09e1f9ebc16533d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Combine lists into a DataFrame\n",
    "df = pd.DataFrame(iterations_results)\n",
    "\n",
    "# File path to save CSV\n",
    "file_path = 'double_segment_crossover.csv'\n",
    "\n",
    "# Write DataFrame to CSV\n",
    "df.to_csv(file_path, index=False, header=False)\n",
    "\n",
    "print(f\"Data has been saved to {file_path}\")"
   ],
   "id": "90490cd5a18e522b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## alternating_parental_gene_crossover",
   "id": "9a859d60ebe999a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import multiprocessing\n",
    "\n",
    "# Function to run\n",
    "def run():\n",
    "    best_chromosome, best_fitness, gen = genetic_algorithm(Jobs, population_size=8, generations=500,\n",
    "                      mutation_rate=0.01, fitness_function=get_makespan, satisfication_vlue=0,\n",
    "                      crossover_function=alternating_parental_gene_crossover)\n",
    "    return gen\n",
    "\n",
    "# Number of iterations\n",
    "num_iterations = 100\n",
    "\n",
    "# Define a function for parallel execution\n",
    "def parallel_run(index):\n",
    "    print(f\"Running iteration {index}\")\n",
    "    return index, run()  # Return both the iteration index and the result\n",
    "\n",
    "# Number of CPU cores\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(num_cores)\n",
    "\n",
    "# Run the loop in parallel\n",
    "with multiprocessing.Pool(num_cores) as pool:\n",
    "    results = pool.map(parallel_run, range(num_iterations))\n",
    "\n",
    "# Sort results based on the iteration index\n",
    "results.sort(key=lambda x: x[0])\n",
    "\n",
    "# Extract only the results and store them in a list\n",
    "iterations_results = [result[1] for result in results]\n",
    "\n",
    "# Print the results (optional)\n",
    "print(iterations_results)"
   ],
   "id": "65018d468bb5b212",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Combine lists into a DataFrame\n",
    "df = pd.DataFrame(iterations_results)\n",
    "\n",
    "# File path to save CSV\n",
    "file_path = 'alternating_parental_gene_crossover.csv'\n",
    "\n",
    "# Write DataFrame to CSV\n",
    "df.to_csv(file_path, index=False, header=False)\n",
    "\n",
    "print(f\"Data has been saved to {file_path}\")"
   ],
   "id": "5a80be220222c6a4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
